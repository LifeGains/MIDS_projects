{"cells":[{"cell_type":"markdown","source":["# Flight's On-Time Performance Data\n\nThis notebook contains On-time performance of different airlines from 2015 - 2019. In this notebook we present Exploratory Data Analysis (EDA), feature engineering and creation on this dataset."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7cf5fcd9-b34f-4830-9ad3-732f93719a5d"}}},{"cell_type":"markdown","source":["## Data Storage and Import"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df17130c-e783-462c-9506-94f7c26fd2f1"}}},{"cell_type":"markdown","source":["#### Set Up The Blob"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b2587ef-42e6-488e-8c0c-b5af43ef8132"}}},{"cell_type":"code","source":["# Init script to create the blob URL\n# Put this at the top of every notebook\nfrom pyspark.sql.functions import col, max\n\nblob_container = \"team07\" # The name of your container created in https://portal.azure.com\nstorage_account = \"team07\" # The name of your Storage account created in https://portal.azure.com\nsecret_scope = \"team07\" # The name of the scope created in your local computer using the Databricks CLI\nsecret_key = \"team07\" # The name of the secret key created in your local computer using the Databricks CLI \nblob_url = f\"wasbs://{blob_container}@{storage_account}.blob.core.windows.net\"\nmount_path = \"/mnt/mids-w261\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2631ed3f-5e9c-45ef-b67b-c875ac9750ee"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Generates the SAS token\n# Put this at the top of every notebook\nspark.conf.set(\n  f\"fs.azure.sas.{blob_container}.{storage_account}.blob.core.windows.net\",\n  dbutils.secrets.get(scope = secret_scope, key = secret_key)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7b5b6b4-a771-47c5-b047-42d264905ff8"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Source: https://ucbischool.slack.com/archives/C02C3SFLC11/p1635569501096100?thread_ts=1635526204.076500&cid=C02C3SFLC11 \n# Displays what is currently in the blob\n# Put this at the top of every notebook\ndisplay(dbutils.fs.ls(blob_url))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0d8cd3d-fc98-4e60-b769-cc72c38ad6a8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Run Imports"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d046af9-f571-4b72-931a-4cdd8479bfdf"}}},{"cell_type":"code","source":["pip install timezonefinder"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66f425ac-c755-4d48-99a8-be5b1672eafa"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["pip install geopy"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66b69c93-a896-4a06-b448-cfa3b1363bbb"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#ALL IMPORTS\nimport re\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport pyspark\nimport matplotlib.pyplot as plt\nfrom pyspark.sql.functions import col\nfrom pyspark.sql import functions as sf\nfrom geopy.geocoders import Nominatim\nfrom timezonefinder import TimezoneFinder\nfrom datetime import datetime \nfrom pyspark.sql.functions import split\nimport pytz\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import concat,col\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.types import TimestampType\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.types import StringType\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql.functions import col,sum\nfrom pyspark.sql.functions import desc\nfrom pyspark.sql.functions import rank\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import col,sum"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5867766-04bc-448a-abae-3e0fc7e172cd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Inspect the Mount's Final Project folder \ndisplay(dbutils.fs.ls(\"/mnt/mids-w261/datasets_final_project\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4201e233-5e80-4760-ada4-8947b3098b88"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Load Full Airlines Dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"269cf923-fae6-45a9-9593-a66a9d5f6fa1"}}},{"cell_type":"code","source":["#Load all Flights Data\ndf_airlines = spark.read.parquet(\"/mnt/mids-w261/datasets_final_project/parquet_airlines_data/*\")\n#display(df_airlines)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05f8a7a5-3743-40ab-842a-7dc9573f8fb5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## EDA AIRLINES DATA"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e4a6ca0a-fbf5-4567-b252-aabbbef5c6ba"}}},{"cell_type":"markdown","source":["#### Identify and De-duplicate data\nOn our initial exploration we found that the airlines dataset had over 63 million rows but were duplicated. We dropped these duplicates and the final de-duplicated count for airlines dataset was ~ 31 million. We will be working on this new de-duplicated dataset from this point."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"888a2db3-1c17-4236-ae99-85129dabf82b"}}},{"cell_type":"code","source":["#Original count\nrow_org = df_airlines.count()\nprint(\"Original row count\", row_org)\n\n#Identify duplicates in airlines dataset\ndistinctDF = df_airlines.distinct()\nprint(\"Distinct count: \"+str(distinctDF.count()))\n\n#Drop duplicate rows identified\ndf_airlines = df_airlines.dropDuplicates()\nrow = df_airlines.count()\nprint(\"De-duplicated row count\", row)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0df585ed-301e-4e31-9cff-2710fce57a53"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# extracting number of columns from the Dataframe\ncolumn = len(df_airlines.columns)\ncolumn"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9023c570-7c82-4138-84fe-cd70e5100dac"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### General Descriptives and Frequencies for columns of interest"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25e60051-b86a-4759-a9bf-11558e414319"}}},{"cell_type":"markdown","source":["We ran descriptive statistics on some columns of interest to understand flight characteristics, delayed times and reasons for delay. On running these some highlight results were that Late aircraft and Carrier delay reasons have highest average delay in minutes compared across other reasons. Most flights were short distance (~800 miles) and roughly little over 2 hours, average delay in departure and arrival was roughly 12 minutes. This is in line with our definition of delayed flights for this project where any flight with delay > 15 minutes is regarded as delayed."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"31a72e12-81c5-4a49-a880-fda1c1451448"}}},{"cell_type":"code","source":["# Descriptive statistics on some columns of interest to understand flight characteristics, delayed times and reasons for delay\ndf_airlines.select(['DEP_DELAY_NEW', 'ARR_DELAY_NEW','TAXI_OUT', 'AIR_TIME', 'ACTUAL_ELAPSED_TIME',\n           'DISTANCE','CARRIER_DELAY','WEATHER_DELAY','NAS_DELAY','SECURITY_DELAY','LATE_AIRCRAFT_DELAY']).describe().toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e32b6265-c003-4c0e-be2d-664a1c81cebe"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["- On further exploring categorical data we looked at our outcome variable \"DEP_DEl15\" which is a departure delay indicator of 15 Minutes or More (1=Yes). On observing the counts for delayed flights we realized that only ~18% of the flights were classfied as delayed. This highlighted the imabalance in our dataset of the outcome feature. In our ML algorithm implementation we have used methods (Over-representation of minority class) to balance this dataset. \n- Majority (~80%) of the delayed departing flights had delayed previous arriving flights. Chicago, Atlanta, NY and Dallas-FortWorth were the most popular airports with high number of departing and arriving flights.\n- The dataset also had ~1.6% cancelled and very few ~0.2% diverted flights. On observing the reasons for cancelled flight from cancellation code, the flights were split acorss various reasons and weather was not the only reason, Also these flights never departed so we could not acurately infer our outcome indicator DEP_DEL15. To be clean and precise we decided to remove the cancelled flights from our dataset. We decided to leave the diverted flights as such because they were very few to begin with and there could be lot of reasons for diversions (including weathe)r which we wanted to account for in our analysis."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8b58dea-47b0-4612-b0fd-2d2333dcbcb0"}}},{"cell_type":"code","source":["#Frequency tables for categorical data in columns of interest to understand delayed, cancelled and diverted flights\nfreq_table_year = df_airlines.groupBy(\"YEAR\").count().orderBy('count', ascending=False).show()\nfreq_table_cancel = df_airlines.groupBy(\"CANCELLED\").count().cache().show()\nfreq_table_cancel = df_airlines.groupBy(\"DIVERTED\").count().show()\nfreq_table_delay = df_airlines.groupBy(\"DEP_DEL15\").count().cache().show()\nfreq_table_arrdelay = df_airlines.groupBy(\"ARR_DEL15\").count().cache().show()\narrival_delay = df_airlines.crosstab('DEP_DEL15','ARR_DEL15').show()\ncancel_delay = df_airlines.crosstab('CANCELLED', 'DEP_DEL15').show()\norigin_table = df_airlines.groupBy(\"ORIGIN_CITY_NAME\").count().orderBy('count', ascending=False).show()\ndestination_table = df_airlines.groupBy(\"DEST_CITY_NAME\").count().orderBy('count', ascending=False).show()\ncancelreason_table = df_airlines.crosstab(\"CANCELLED\",\"CANCELLATION_CODE\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aab31631-959e-4baf-9016-d09bb355696b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Missing Data\nWe observed several columns (especially related to diveretd flights) had high number of missing values. We took a high benchmark threshold of 96% and any columns with missing values > 96% of the total data were excluded from the dataset. Below we report the columns that were deleted. The dataset originally had 109 columns and after removing there were 61 columns left."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ccf8cb97-86c8-4a34-9825-667060fc0e1b"}}},{"cell_type":"code","source":["#Looking for Missing values\nmissing_df = df_airlines.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in df_airlines.columns)).toPandas()\nmissing_df"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dda0382c-b117-4323-b2d4-8961956b35c1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Handling Missing Values: Deleting columns with missing data greater than 96%  \ntotal = df_airlines.count()\nthreshold = 0.96 * total #threshold to delete\ncols_to_drop = []\nfor col in missing_df.columns:\n  val = missing_df[col].values[0]\n  if val > threshold:\n    cols_to_drop.append(col)\n  else:\n    pass\nprint(cols_to_drop) #list of cols to delete\nprint(\"total:\", total, \"threshold to drop:\", threshold)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88900d00-988a-451c-b31d-c81744d3892c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#drop cols list to be deleted\ndf_airlines_new = df_airlines.drop(*cols_to_drop) \ncolumn_new = len(df_airlines_new.columns)\nprint(\"Number of columns after handling missing data\", column_new)\n#display(df_airlines_new)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5516f88-a81c-4d87-bf27-70cdedc14dcf"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Correlation matrix\nTo understand multicollinearity in our dataset we built a correlation matrix looking at peasrson correlations for potential columsn of interest that we plan to include in our final model. Looking at the coefficients we see that Quarter and month; Departure delay and Arrival delay; Actual elapsed time and Distance have high correlations (> 0.95)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5637a2e-55f1-4618-976b-16815c88b1e4"}}},{"cell_type":"code","source":["from pyspark.ml.stat import Correlation\nfrom pyspark.ml.feature import VectorAssembler\n\n# get non-string columns of interest\ndf_small = df_airlines_new[['DEP_DEL15','YEAR','QUARTER','MONTH','DAY_OF_WEEK','DAY_OF_MONTH','ORIGIN_AIRPORT_ID','OP_CARRIER_AIRLINE_ID','DEST_AIRPORT_ID','CRS_DEP_TIME','DEP_DELAY','ARR_DELAY','ACTUAL_ELAPSED_TIME','DISTANCE','CARRIER_DELAY','WEATHER_DELAY','NAS_DELAY','SECURITY_DELAY','LATE_AIRCRAFT_DELAY' ]].fillna(0)\n\n# convert to vector column first\nvector_col = \"corr_features\"\nassembler = VectorAssembler(inputCols=df_small.columns, outputCol=vector_col)\ndf_vector = assembler.transform(df_small).select(vector_col)\n\n# get correlation matrix\nmatrix = Correlation.corr(df_vector, vector_col)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbcded38-57bc-48d4-95e1-791becbcda36"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["\nmatrix.collect()[0][\"pearson({})\".format(vector_col)].values\ncor_np = matrix.collect()[0][\"pearson({})\".format(vector_col)].values\ndim = len(cor_np)\ncor_mat = cor_np.reshape( (19,19) )\nfig, ax = plt.subplots(figsize=(24,24))\nsns.heatmap(cor_mat, annot=True, fmt='.2f', cmap = sns.cm.rocket_r)\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7c55a32-6ad5-4548-9f5c-5b5cf3629a2e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Cancelled Flights\nWe explained our observations for cancelled flights above and decidied to remove the from the dataset. Below is the filter operation to accomlish this."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c866f9b-f817-4aeb-b225-403473f976fe"}}},{"cell_type":"code","source":["# Unable to classify with accuracy if cancelled flights were delayed due to weather. Few are marked as delayed or not and for majority delayed status is null. We will exclude all the cancelled flights.Diverted flights will be left as such because there could be lot of reasons for diversions and weather could be one of them. We dont want to loose them.\n\n#No. of diverted flights that were cancelled\ncancel_time = df_airlines_new.crosstab('DIVERTED', 'CANCELLED').toPandas() \n\n#Filter out cancelled flights\ndf_airlines_filter = df_airlines_new.where(df_airlines_new.CANCELLED != 1.0).cache()\n#display(df_airlines_filter)\n\nfreq_table_cancel = df_airlines_filter.groupBy(\"CANCELLED\").count().show() #confirm no cancelled flights remaining\n "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e709741c-2bd4-41f6-8f79-a717039e8266"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## EDA to understand trends and patterns in data\nBased on our initial EDA and get an idea about which features to explore and engineer we looked at some trends and patterns in our dataset. The headers below describe our highlights from these patterns."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4041ba94-871c-471c-a830-cf5706339f0b"}}},{"cell_type":"code","source":["# create TempView to allow SQL queries\ndf_airlines.createTempView(\"airlines\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"58cf744d-5d0a-4842-a303-441a39051c03"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### _More than 20% of flights delay more than 15 minutes_"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd9b670e-0640-4076-b409-51ac7e0fcb5e"}}},{"cell_type":"code","source":["# query departure delay data\ndelay_hist_df = spark.sql(\"SELECT dep_delay FROM airlines ORDER BY dep_delay ASC\").na.drop().toPandas()\n# set-up a new figure with white facecolor\nplt.figure(figsize=(10, 5), facecolor='white')\n# set-up a new axes\nax = plt.subplot(1, 1, 1)\n# set plot appearance\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['bottom'].set_color('#C4B6BC')\nax.spines['left'].set_color('#C4B6BC')\nax.tick_params(axis='x', colors='#75686D')\nax.tick_params(axis='y', colors='#75686D')\n# plot the histogram\nN, bins, patches = ax.hist(x=delay_hist_df.dep_delay.tolist(), cumulative=True, density=True, bins=10000, histtype='bar', data=delay_hist_df)\nfor i in range(0,345):\n    patches[i].set_facecolor('#dedede')\nfor i in range(345, len(patches)):\n    patches[i].set_facecolor('#3D6197')\n# place plot title\nplt.title(r'Departure delay cumulative distribution', pad=22, fontsize=15, x=0.38, color='#75686D')\n# place vertical and horizontal lines\n#plt.text(x=2, y=0.99, s='23% of flights delayed more than 15 min', fontsize=15, color='#3D6197', fontweight='bold')\n# set y axis params\nplt.ylabel('cdf', fontsize=12, labelpad=10, color='#75686D')\nplt.yticks(np.arange(0.0, 1.2, step=0.2))\nplt.ylim((0.0, 1.0))\n# x axis params\nplt.xlabel('Delay (in minutes)', fontsize=12, labelpad=10, color='#75686D')\nplt.xticks(np.arange(0, 105, step=15))\nplt.xlim((0, 90))\n# display results\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9caedd37-c160-45a6-9c55-e409cf798b2a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### _Majority of delays caused by own carrier or late aircrafts_"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0208a4b7-092b-40a5-9d5b-c3bc28ed802c"}}},{"cell_type":"code","source":["# query departure delay data\ndelay_reasons_df = spark.sql(\"SELECT SUM(carrier_delay), SUM(late_aircraft_delay), SUM(nas_delay), SUM(weather_delay), SUM(security_delay) FROM airlines\").toPandas()\n# re-scale values dividing per 1,000\ndelay_reasons_df = delay_reasons_df/1000\n# rename column names\nnew_col_names = {'sum(carrier_delay)': 'Carrier', 'sum(weather_delay)': 'Weather', 'sum(nas_delay)': 'NAS',\n                 'sum(security_delay)': 'Security', 'sum(late_aircraft_delay)': 'Late aircraft'}\ndelay_reasons_df = delay_reasons_df.rename(new_col_names, axis=1)\n# set-up a new figure with white facecolor\nplt.figure(figsize=(6, 4), facecolor='white')\n# set-up a new axes\nax = plt.subplot(1, 1, 1)\n# set plot appearance\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['bottom'].set_color('#C4B6BC')\nax.spines['left'].set_color('#C4B6BC')\nax.tick_params(axis='x', colors='#75686D', labelsize=12)\nax.tick_params(axis='y', colors='#75686D')\n# plot the barplot\nfor x in delay_reasons_df.columns:\n  if x in ['Carrier', 'Late aircraft']:\n    ax.bar(x, delay_reasons_df[x].values, color='#3D6197')\n  else:\n    ax.bar(x, delay_reasons_df[x].values, color='#dedede')\n# place plot title\nplt.title(r'Root causes for departure delays', pad=20, fontsize=15, x=0.42, color='#75686D')\n# place vertical and horizontal lines\n#plt.text(x=-0.4, y=750, s='Majority of delays caused by carrier or late aircrafts', fontsize=15, color='#3D6197', fontweight='bold')\n# set y axis params\nplt.ylabel('Total delay in 1,000 min', fontsize=12, labelpad=10, color='#75686D')\nplt.yticks(np.arange(0.0, 350000, step=50000))\nplt.ylim((0.0, 350000))\n# display results\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c8e3ebf7-4b38-4241-9cef-45cd94c2e880"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### _Delays are not uniformly distributed over the days_"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d56e20ef-25f2-4575-960d-d8a5e064c684"}}},{"cell_type":"code","source":["# query percentage of delayed flights per day\ncount_delayed_df = spark.sql(\"SELECT month, day_of_month, count(op_carrier_fl_num) FROM airlines WHERE dep_del15==1 GROUP BY month, day_of_month, dep_del15 ORDER BY month, day_of_month\").toPandas()\ncount_total_df = spark.sql(\"SELECT month, day_of_month, count(op_carrier_fl_num) FROM airlines WHERE dep_del15 IS NOT NULL GROUP BY month, day_of_month ORDER BY month, day_of_month\").toPandas()\npct_delayed_df = pd.concat([count_delayed_df,count_total_df], axis=1)\npct_delayed_df.columns = ['month', 'day_of_month', 'count_delayed', 'month_2', 'day_of_month_2', 'count_total']\npct_delayed_df['pct_delayed'] = pct_delayed_df['count_delayed']/pct_delayed_df['count_total']\npct_delayed_df['date'] = pct_delayed_df['month'].astype(str) + '/' + pct_delayed_df['day_of_month'].astype(str)\npct_delayed_df = pct_delayed_df.drop(['month', 'day_of_month', 'month_2', 'day_of_month_2', 'count_delayed', 'count_total'], axis=1)\n# set-up a new figure with white facecolor\nplt.figure(figsize=(15, 6), facecolor='white')\n# set-up a new axes\nax = plt.subplot(1, 1, 1)\n# set plot appearance\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['bottom'].set_color('#C4B6BC')\nax.spines['left'].set_color('#C4B6BC')\nax.tick_params(axis='x', colors='#75686D')\nax.tick_params(axis='y', colors='#75686D')\n# plot the lineplot\nax.plot(pct_delayed_df['date'], pct_delayed_df['pct_delayed'], color='#3D6197', linestyle='-', linewidth=2)\n# place plot title\nplt.title(r'Departure delay incidence over time', pad=22, fontsize=15, x=0.36, color='#75686D')\n# place vertical and horizontal lines\n#plt.text(x=5, y=0.6, s='Delays tend to concentrate on specific days', fontsize=15, color='#3D6197', fontweight='bold')\n# set y axis params\nplt.ylabel('Pct of flights with delays >15min', fontsize=12, labelpad=9, color='#75686D')\nplt.yticks(np.arange(0.0, 0.7, step=0.1))\nplt.ylim((0.0, 0.6))\n# x axis params\nevery_nth = 20\nfor n, label in enumerate(ax.xaxis.get_ticklabels()):\n    if n % every_nth != 0:\n        label.set_visible(False)\nax.tick_params(axis='both', which='both', length=0)\n# display results\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ff4aa8a3-30db-4e20-be54-16a31be65768"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### _Delays are not uniformly distributed among the airlines_"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4790e0c-8002-4c38-bda7-973fef80df4f"}}},{"cell_type":"code","source":["# query percentage of delayed flights per airline\ncount_delayed_by_airline_df = spark.sql(\"SELECT op_carrier_airline_id, count(op_carrier_fl_num) AS count_delayed FROM airlines WHERE dep_del15==1 GROUP BY op_carrier_airline_id ORDER BY count(op_carrier_fl_num) DESC\").toPandas()\ncount_total_by_airline_df = spark.sql(\"SELECT op_carrier_airline_id, count(op_carrier_fl_num) AS count_total FROM airlines WHERE dep_del15 IS NOT NULL GROUP BY op_carrier_airline_id ORDER BY count(op_carrier_fl_num) DESC\").toPandas()\ncount_delayed_by_airline_df.set_index('op_carrier_airline_id', inplace=True)\ncount_total_by_airline_df.set_index('op_carrier_airline_id', inplace=True)\npct_delayed_by_airline_df = count_delayed_by_airline_df.join(count_total_by_airline_df)\npct_delayed_by_airline_df = pct_delayed_by_airline_df[pct_delayed_by_airline_df['count_total']>1000]\npct_delayed_by_airline_df['pct_delayed'] = pct_delayed_by_airline_df['count_delayed']/pct_delayed_by_airline_df['count_total']\npct_delayed_by_airline_df = pct_delayed_by_airline_df.drop(['count_delayed', 'count_total'], axis=1)\npct_delayed_by_airline_df.sort_values(by='pct_delayed', axis=0, ascending=False, inplace=True)\n# set-up a new figure with white facecolor\nplt.figure(figsize=(15, 6), facecolor='white')\n# set-up a new axes\nax = plt.subplot(1, 1, 1)\n# set plot appearance\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['bottom'].set_color('#C4B6BC')\nax.spines['left'].set_color('#C4B6BC')\nax.tick_params(axis='x', colors='#75686D', labelsize=12)\nax.tick_params(axis='y', colors='#75686D')\n# plot the barplot\nfor x in pct_delayed_by_airline_df.index:\n  ax.bar(str(x), pct_delayed_by_airline_df.loc[x, 'pct_delayed'], color='#3D6197')\n# place plot title\nplt.title(r'Delay incidence per airline', pad=22, fontsize=15, x=0.27, color='#75686D')\n# place vertical and horizontal lines\n#plt.text(x=-0.4, y=0.48, s='Delays tend to concentrate on specific airlines', fontsize=15, color='#3D6197', fontweight='bold')\n# set y axis params\nplt.ylabel('Pct of flights with delays >15min', fontsize=12, labelpad=9, color='#75686D')\nplt.yticks(np.arange(0.0, 0.6, step=0.1))\nplt.ylim((0.0, 0.5))\n# set x axis params\nplt.xlabel('Airline ID', fontsize=12, labelpad=12, color='#75686D')\n# display results\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d2285631-e3f4-4c64-b1a2-63931c132607"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### _Delays are not uniformly distributed among the origin airports_"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c60ce882-ace9-4692-83d6-14cccc6ce1d7"}}},{"cell_type":"code","source":["# query percentage of delayed flights per airport\ncount_delayed_by_airport_df = spark.sql(\"SELECT origin, count(op_carrier_fl_num) AS count_delayed FROM airlines WHERE dep_del15==1 GROUP BY origin ORDER BY count_delayed DESC\").toPandas()\ncount_total_by_airport_df = spark.sql(\"SELECT origin, count(op_carrier_fl_num) AS count_total FROM airlines WHERE dep_del15 IS NOT NULL GROUP BY origin ORDER BY count_total DESC\").toPandas()\ncount_delayed_by_airport_df.set_index('origin', inplace=True)\ncount_total_by_airport_df.set_index('origin', inplace=True)\npct_delayed_by_airport_df = count_delayed_by_airport_df.join(count_total_by_airport_df)\npct_delayed_by_airport_df['pct_delayed'] = pct_delayed_by_airport_df['count_delayed']/pct_delayed_by_airport_df['count_total']\npct_delayed_by_airport_df = pct_delayed_by_airport_df.drop(['count_delayed', 'count_total'], axis=1)\npct_delayed_by_airport_df.sort_values(by='pct_delayed', axis=0, ascending=False, inplace=True)\n# set-up a new figure with white facecolor\nplt.figure(figsize=(15, 6), facecolor='white')\n# set-up a new axes\nax = plt.subplot(1, 1, 1)\n# set plot appearance\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['bottom'].set_color('#C4B6BC')\nax.spines['left'].set_color('#C4B6BC')\nax.tick_params(axis='x', colors='#75686D', labelsize=12)\nax.tick_params(axis='y', colors='#75686D')\n# plot the barplot\nfor x in pct_delayed_by_airport_df.index:\n  ax.bar(str(x), pct_delayed_by_airport_df.loc[x, 'pct_delayed'], color='#3D6197')\n# place plot title\nplt.title(r'Delay incidence per origin airport', pad=22, fontsize=15, x=0.43, color='#75686D')\n# place vertical and horizontal lines\n#plt.text(x=-0.4, y=0.48, s='Delays tend to concentrate on specific origin airports', fontsize=15, color='#3D6197', fontweight='bold')\n# set y axis params\nplt.ylabel('Pct of flights with delays >15min', fontsize=12, labelpad=9, color='#75686D')\nplt.yticks(np.arange(0.0, 0.6, step=0.1))\nplt.ylim((0.0, 0.5))\n# set x axis params\nevery_nth = 20\nfor n, label in enumerate(ax.xaxis.get_ticklabels()):\n    if n % every_nth != 0:\n        label.set_visible(False)\nax.tick_params(axis='both', which='both', length=0)\nplt.xlabel('Origin airport', fontsize=12, labelpad=10, color='#75686D')\n# display results\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f21dbfb0-2c07-4467-b184-f56c36c0e974"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### _Delays are not uniformly distributed among the destination airports_"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"10a9f1b2-3096-4fc5-847c-2771ade2465f"}}},{"cell_type":"code","source":["# query percentage of delayed flights per airport\ncount_delayed_by_dest_airport_df = spark.sql(\"SELECT dest, count(op_carrier_fl_num) AS count_delayed FROM airlines WHERE dep_del15==1 GROUP BY dest ORDER BY count_delayed DESC\").toPandas()\ncount_total_by_dest_airport_df = spark.sql(\"SELECT dest, count(op_carrier_fl_num) AS count_total FROM airlines WHERE dep_del15 IS NOT NULL GROUP BY dest ORDER BY count_total DESC\").toPandas()\ncount_delayed_by_dest_airport_df.set_index('dest', inplace=True)\ncount_total_by_dest_airport_df.set_index('dest', inplace=True)\npct_delayed_by_dest_airport_df = count_delayed_by_dest_airport_df.join(count_total_by_dest_airport_df)\npct_delayed_by_dest_airport_df['pct_delayed'] = pct_delayed_by_dest_airport_df['count_delayed']/pct_delayed_by_dest_airport_df['count_total']\npct_delayed_by_dest_airport_df = pct_delayed_by_dest_airport_df.drop(['count_delayed', 'count_total'], axis=1)\npct_delayed_by_dest_airport_df.sort_values(by='pct_delayed', axis=0, ascending=False, inplace=True)\n# set-up a new figure with white facecolor\nplt.figure(figsize=(15, 6), facecolor='white')\n# set-up a new axes\nax = plt.subplot(1, 1, 1)\n# set plot appearance\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['bottom'].set_color('#C4B6BC')\nax.spines['left'].set_color('#C4B6BC')\nax.tick_params(axis='x', colors='#75686D', labelsize=12)\nax.tick_params(axis='y', colors='#75686D')\n# plot the barplot\nfor x in pct_delayed_by_dest_airport_df.index:\n  ax.bar(str(x), pct_delayed_by_dest_airport_df.loc[x, 'pct_delayed'], color='#3D6197')\n# place plot title\nplt.title(r'Delay incidence per destination airport', pad=22, fontsize=15, x=0.37, color='#75686D')\n# place vertical and horizontal lines\n#plt.text(x=5, y=0.49, s='Delays tend to concentrate on specific destination airports', fontsize=15, color='#3D6197', fontweight='bold')\n# set y axis params\nplt.ylabel('Pct of flights with delays >15min', fontsize=12, labelpad=9, color='#75686D')\nplt.yticks(np.arange(0.0, 0.6, step=0.1))\nplt.ylim((0.0, 0.5))\n# set x axis params\nevery_nth = 20\nfor n, label in enumerate(ax.xaxis.get_ticklabels()):\n    if n % every_nth != 0:\n        label.set_visible(False)\nax.tick_params(axis='both', which='both', length=0)\nplt.xlabel('Destination airport', fontsize=12, labelpad=10, color='#75686D')\n#plt.xticks([])\n# display results\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8c238471-c086-44a6-8a48-403d2754647a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Feature Engineering"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6200d4e-4ce8-4bcf-a7ab-ce55db8c6ad0"}}},{"cell_type":"markdown","source":["Based on our observations in the dataset on EDA, main reasons for flight delay in US as reported by the Bureau of Transportation Statistics [7] and fascilitate join with weather dataset, we got some hints about features to explore and engineer. The following features were engineered and added to the full dataset:\n\n- Timestamp reflecting airline scheduled departure date and time: We created a timestamp in utc and unix format by concatenating flight date and CRS_DEP_TIME to fasciliate join with the weather data. Conversion to utc was done as weather data had time in utc format. However when we joined the two datasets together we decided to convert to unix as the join was significantly faster using unix timestamps.\n\n- Timestamp 2 hours prior to scheduled departure time: This was added to the dataset as we will are building models that predict flight delays 2 hours prior to scheduled departure time. This will be regarded as our prediction time and used for further feature engineering related to time of departure.\n\n- Average delayed flights (rolling window 30 days) for every aircraft: was added to account for an aircraft's condition (aging, chronic faults etc.) on flight delays. Unique aircrafts were identified by tail_num.\n\n- Frequency of delays in the departure airport (for all airlines) in the past 2, 4, 8 and 12 hours: to account for local issues in the departing airport may cause a series of flights from different airlines to delay (e.g. weather conditions, security incidents, etc.)\n\n- Frequency of delays in the destination airport (for all airlines) in the past 2, 4, 8 and 12 hours: to account for local issues in the destination airport may cause a series of flights from different airlines to delay in the origin (e.g. weather conditions, security incidents, etc.)\n\n- Frequency of delays in the most important hubs (for all airlines) in the past 2, 4, 8 and 12 hours: to account for local issues in important hubs of the system may cause a series of flight from different airlines in different airports to delay\n\n- Frequency of delays of the same airline (in the departure airport) in the past 2, 4, 8 and 12 hours: to account for majority of delays are classified as under the air carrier control, so a specific carrier previous delays might be a good indicative of operational problems that might propagate\n\n- Frequency of delays of the same airline (in the most important hubs) in the past 2, 4, 8 and 12 hours: to account for operational problems in airport hubs which might propagate faster to the system than isolated problems. We will describe how we identified hubs in the relevant section below.\n\n- Frequency of late arrivals in the departure airport (for all airlines) in the past 2, 4, 8 and 12 hours: late arriving aircrafts are the second most prevalent cause for flight departure delays\n\n- Percentage of flights delayed due to weather every hour: to enable further feature engineering for weather related features we calculated and included % of flights delayed due to weather every hour.\n\n- Part of the day (Morning, Afternoon etc.): to account for the snowball effect of flights getting delayed earlier in the day on flights on flights departing later in the day."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb3289d0-b697-43f7-a13e-36abed7ff46a"}}},{"cell_type":"markdown","source":["### Setting pipeline to create features"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03195f32-4343-423c-a7d0-70d837869b57"}}},{"cell_type":"markdown","source":["##### Creating timestamp reflecting airline scehduled departure date and time"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fa5c10c4-58cf-4541-89bb-266cf114f5f7"}}},{"cell_type":"code","source":["#Create local Timestamp column by joining Flight date and Departure time\ndf_airlines_filter = df_airlines_filter.withColumn('timestamp', \n                    sf.concat(sf.col('FL_DATE'),sf.lit(' '), sf.col('CRS_DEP_TIME')))\n#display(df_airlines_filter)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f352102a-9b4e-45de-b5f5-67d56a045c02"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["User defined function used in feature engineering and creation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c590c3f7-9cf0-4f70-90be-db55095e61ef"}}},{"cell_type":"code","source":["#UDF`s for feature engineering\n\n## UDF for getting timezone from city\ndef time_zone(city):\n  # initialize Nominatim API\n  geolocator = Nominatim(user_agent=\"geoapiExercises\")\n  \n  if \"/\" in city: #take first city of airports serving MSA`s \n    city=city.split(\"/\")[0]\n\n  #get long and latitude\n  location = geolocator.geocode(city) #location.latitude and location.longitude\n  #print(\"city:\",city)\n  #print(\"lngitude:\", location.longitude)\n\n  # pass the Latitude and Longitud into a timezone_at and return timezone\n  obj = TimezoneFinder()\n  result = obj.timezone_at(lng=location.longitude, lat=location.latitude)\n  return result\n\n\n## UDF Convert local time timestamp to utc timestamp using timezones\ndef utc_converter(timezone, time):\n  local = pytz.timezone(timezone)\n  #naive = datetime.strptime(\"2015-02-10 1729\", \"%Y-%m-%d %H%M\")\n  if time != \"\":\n    naive = datetime.strptime(time, \"%Y-%m-%d %H%M\")\n    local_dt = local.localize(naive, is_dst=None)\n    utc_dt = local_dt.astimezone(pytz.utc)\n  else:\n    utc_dt = \"Null\"\n  return utc_dt\n\ndef utc_converter2(timezone, time):\n  try:\n    local = pytz.timezone(timezone)\n    naive = datetime.strptime(time, \"%Y-%m-%d %H%M\")\n    local_dt = local.localize(naive, is_dst=None)\n    utc_dt = local_dt.astimezone(pytz.utc).strftime(\"%Y-%m-%dT%H:%M:%S\")\n  except:\n    return None\n  return utc_dt\n\n#UDF for port hub status\ndef hub_port(rank): \n  if rank <= 15: #took top 15 airports with maximum total(arriving and departing flights) as hubs\n    port = \"hub\"\n  else:\n    port = \"non-hub\"\n  return port"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ed20b1e2-8c4e-4749-bc7e-c60397f39aee"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Identify airports as hubs\nIn order to label airports as hubs we calculated the total number of arriving and departing flights from every airport and then ranked them based on the count. The top 15 airports were classified as hubs and rest as non-hubs and this was added as a column."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77032277-d2b5-4218-8431-3d5883b88911"}}},{"cell_type":"code","source":["from pyspark.sql.functions import col\ntab_origin = df_airlines.groupBy(\"ORIGIN_AIRPORT_ID\").count().withColumnRenamed(\"ORIGIN_AIRPORT_ID\", \"AIRPORT_ID\") #total flights from origin\ndisplay(tab_origin)\ntab_dest = df_airlines.groupBy(\"DEST_AIRPORT_ID\").count().withColumnRenamed(\"DEST_AIRPORT_ID\", \"AIRPORT_ID\") #total flights from dest\ndisplay(tab_dest)\nresult = tab_origin.unionByName(tab_dest) #union of both\ndisplay(result)\nresult2 = result.groupBy(\"AIRPORT_ID\").sum('count').orderBy('sum(count)', ascending=False) #total sum every airport\ndisplay(result2)\nwindowSpec  = Window.partitionBy().orderBy(col(\"sum(count)\").desc()) \nresult3 = result2.withColumn(\"airport_rank\",rank().over(windowSpec)) #ranking\ndisplay(result3)\n\n#using udf to main dataframe\nHubUDF = udf(lambda z: hub_port(z),StringType())\nresult4= result3.withColumn(\"hub_status\", HubUDF(sf.col(\"airport_rank\")))\n\n#result4.withColumn(\"json\", sf.create_map([\"AIRPORT\", \"dma\"])).show(truncate=False)\nhub_lookup = {row['AIRPORT_ID']:row['hub_status'] for row in result4.collect()}\n\n# Applying hub lookup UDF on spark dataframe to create port_hub_status column\nhub_mainUDF = udf(lambda z: hub_lookup[z], returnType= StringType())\n\n#using lookup table to update main dataframe\ndf_airlines_filter = df_airlines_filter.withColumn(\"origin_hub_status\", hub_mainUDF(sf.col(\"ORIGIN_AIRPORT_ID\")))\ndf_airlines_filter = df_airlines_filter.withColumn(\"dest_hub_status\", hub_mainUDF(sf.col(\"DEST_AIRPORT_ID\")))\n#display(df_airlines_filter)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32dad4b2-954c-4c59-9a15-9f8729cd4851"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Converting timestamp into utc and unix format\nWe had to addtional engineering as timestamp we created were in local times in the airlines datset. We used the geolocator 'nominatim' API to add time zones to every airport and then used it to get the utc and unix times."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71bdd3f8-e413-4e0a-9970-808587ea8890"}}},{"cell_type":"code","source":["#split city,state into city\nfrom pyspark.sql.functions import split\nfrom pyspark.sql.functions import col,sum\ndf_airlines_filter = df_airlines_filter.withColumn(\"ORG_CITY\", split(col(\"ORIGIN_CITY_NAME\"), \",\").getItem(0))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e4d2310-6f9e-4450-83d7-5de0a2958bef"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["uniq_cities = df_airlines_filter.agg(sf.collect_set('ORG_CITY')).first() # Creating static Lookup table for cities\ncity_to_timezone_lookup = {city: time_zone(city) for city in uniq_cities[0]} #static lookup table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90526393-7035-4cd1-8c29-32b18654494b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Applying city_to_timezone_lookup UDF on spark dataframe to create timezone column\nTimezoneUDF = udf(lambda z: city_to_timezone_lookup[z], returnType= StringType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"586979d9-ccff-443b-9770-fae666acfd07"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_airlines_filter = df_airlines_filter.withColumn(\"time_zone\", TimezoneUDF(sf.col(\"ORG_CITY\")))\ndisplay(df_airlines_filter)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd99bf6c-24c3-4e66-a440-5339e495b5cc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Applying utc_converter on spark dataframe to create utc_timestamp column\nutf_UDF = udf(utc_converter2) #TimestampType())\ndf_airlines_filter = df_airlines_filter.withColumn('utc_timestamp', utf_UDF('time_zone','timestamp'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad8a971f-de40-40ef-a8ad-a555c546e71b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#convert utc timestamp to unix timestamp\ndf_airlines_filter = df_airlines_filter.withColumn('depart_unix_timestamp', sf.unix_timestamp(sf.col('utc_timestamp'), \"yyyy-MM-dd'T'HH:mm:ss\"))\n#display(df_airlines_filter)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9275cb65-58ea-4531-98fb-704d7ad8e249"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Adding prediction time feature\nThis is the time that was used to create further features related to average delays an frequency of delays for all airports and airlines."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"efca0ccb-93cc-49e9-9ee0-0a92703c7cf4"}}},{"cell_type":"code","source":["#Calculating unix time 2 hrs prior to departure time stamp for feature engineering\ndf_airlines_filter = df_airlines_filter.withColumn(\"depart_unix_prior2hr\", sf.col(\"depart_unix_timestamp\")- 7200)\ndisplay(df_airlines_filter)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6ca8891-53d6-4735-a7f8-b0a37a4acf16"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Average delayed flights (rolling window 30 days) for every aircraft"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd24e3f0-59f1-4467-94dd-9f0aa6f43ad3"}}},{"cell_type":"code","source":["#Average delayed flights per aircraft\nfrom pyspark.sql.window import Window\n#function to calculate number of seconds from number of days\ndays = lambda i: i * 86400\nw = Window().partitionBy(sf.col(\"TAIL_NUM\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-days(30), 0)\nairlines_rolling = df_airlines_filter.withColumn('rolling_average', sf.avg(\"DEP_DEL15\").over(w))\ndisplay(airlines_rolling)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d316598b-f728-4983-87b0-ade3347c6deb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Frequency of delayed flights at origin and destination airport for all airlines in the past 2, 4, 8 and 12 hours"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a66bb54c-1c8c-4d66-919c-09ce7f1f70bf"}}},{"cell_type":"code","source":["#Frequency for delayed flights at origin airport for all airlines\nfrom pyspark.sql.window import Window\n#function to calculate number of seconds from hours\nhours = lambda i: i * 3600\nw = Window().partitionBy(sf.col(\"ORIGIN\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(2), 0)\nairlines_rolling_originairport_2 = airlines_rolling.withColumn('delay_2hrs_originport', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"ORIGIN\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(4), 0)\nairlines_rolling_originairport_4 = airlines_rolling_originairport_2.withColumn('delay_4hrs_originport', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"ORIGIN\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(8), 0)\nairlines_rolling_originairport_8 = airlines_rolling_originairport_4.withColumn('delay_8hrs_originport', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"ORIGIN\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(12), 0)\nairlines_rolling_originairport_12 = airlines_rolling_originairport_8.withColumn('delay_12hrs_originport', sf.sum(\"DEP_DEL15\").over(w))\ndisplay(airlines_rolling_originairport_12)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a85dcd0-9a38-4fd0-91b8-af41b5302eaa"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Rolling frequency of delayed flights at destination airport\n#function to calculate number of seconds from hours\nhours = lambda i: i * 3600\nw = Window().partitionBy(sf.col(\"DEST\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(2), 0)\nairlines_rolling_destairport_2 = airlines_rolling_originairport_12.withColumn('delay_2hrs_destport', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"DEST\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(4), 0)\nairlines_rolling_destairport_4 = airlines_rolling_destairport_2.withColumn('delay_4hrs_destport', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"DEST\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(8), 0)\nairlines_rolling_destairport_8 = airlines_rolling_destairport_4.withColumn('delay_8hrs_destport', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"DEST\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(12), 0)\nairlines_rolling_destairport_12 = airlines_rolling_destairport_8.withColumn('delay_12hrs_destport', sf.sum(\"DEP_DEL15\").over(w))\ndisplay(airlines_rolling_destairport_12)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1aa966e1-c4bd-4cdd-ad81-46d5057d979d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Frequency of delayed flights by airlines in the past 2, 4, 8 and 12 hours"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bec48004-fd0b-4350-936d-7a527127431d"}}},{"cell_type":"code","source":["#frequency for delayed flights by airlines at departure airport\n#function to calculate number of seconds from hours\nhours = lambda i: i * 3600\nw = Window().partitionBy(sf.col(\"OP_CARRIER_AIRLINE_ID\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(2), 0)\nairlines_rolling_originairline_2 = airlines_rolling_destairport_12.withColumn('delay_2hrs_orgairline', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"OP_CARRIER_AIRLINE_ID\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(4), 0)\nairlines_rolling_originairline_4 = airlines_rolling_originairline_2.withColumn('delay_4hrs_orgairline', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"OP_CARRIER_AIRLINE_ID\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(8), 0)\nairlines_rolling_originairline_8 = airlines_rolling_originairline_4.withColumn('delay_8hrs_orgairline', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"OP_CARRIER_AIRLINE_ID\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(12), 0)\nairlines_rolling_originairline_12 = airlines_rolling_originairline_8.withColumn('delay_12hrs_orgairline', sf.sum(\"DEP_DEL15\").over(w))\ndisplay(airlines_rolling_originairline_12)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cff5ff40-432b-4fd8-84d7-280586b763e1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Frequency of late arrivals in the departure airport (for all airlines) in the past 2, 4, 8 and 12 hours"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c2bb85c-fd46-48e9-aa03-7e3566552605"}}},{"cell_type":"code","source":["#Frequency of late arrivals in the departure airport (for all airlines) in the past 2, 4, 8 and 12 hours\n#function to calculate number of seconds from hours\nhours = lambda i: i * 3600\nw = Window().partitionBy(sf.col(\"ORIGIN\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(2), 0)\nairlines_arrdelay_originairport_2 = airlines_rolling_originairline_12.withColumn('arrdelay_2hrs_originport', sf.sum(\"ARR_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"ORIGIN\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(4), 0)\nairlines_arrdelay_originairport_4 = airlines_arrdelay_originairport_2.withColumn('arrdelay_4hrs_originport', sf.sum(\"ARR_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"ORIGIN\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(8), 0)\nairlines_arrdelay_originairport_8 = airlines_arrdelay_originairport_4.withColumn('arrdelay_8hrs_originport', sf.sum(\"ARR_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"ORIGIN\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(12), 0)\nairlines_arrdelay_originairport_12 = airlines_arrdelay_originairport_8.withColumn('arrdelay_12hrs_originport', sf.sum(\"ARR_DEL15\").over(w))\ndisplay(airlines_arrdelay_originairport_12)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29a233f9-5887-4f78-a275-e055ad2d45ca"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Frequency of delays of airlines in the most important hubs in the past 2, 4, 8 and 12 hours"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e2dea92-adab-438c-bb6b-5bbde29a83e0"}}},{"cell_type":"code","source":["#Frequency of delays of the same airline (in the most important hubs) in the past 2, 4, 8 and 12 hours\n#function to calculate number of seconds from hours\nhours = lambda i: i * 3600\nw = Window().partitionBy(sf.col(\"origin_hub_status\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(2), 0)\nairlines_delay_huborigin_2 = airlines_arrdelay_originairport_12.withColumn('delay_2hrs_originhub', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"origin_hub_status\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(4), 0)\nairlines_delay_huborigin_4 = airlines_delay_huborigin_2.withColumn('delay_4hrs_originhub', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"origin_hub_status\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(8), 0)\nairlines_delay_huborigin_8 = airlines_delay_huborigin_4.withColumn('delay_8hrs_originhub', sf.sum(\"DEP_DEL15\").over(w))\nw = Window().partitionBy(sf.col(\"origin_hub_status\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(12), 0)\nairlines_delay_huborigin_12 = airlines_delay_huborigin_8.withColumn('delay_12hrs_originhub', sf.sum(\"DEP_DEL15\").over(w))\ndisplay(airlines_delay_huborigin_12)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3aef1bc4-2b27-4511-ac6c-08174289d3f5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Percentage of flights delayed due to weather every hour\n\nThe weather_delay feature gives the number of minutes a flight was delayed due to weather. However no identifier was available to indicate  if a flight was delayed due to weather. We created an indicator feature for this. If a flight was delayed (as there were some flights which had weather delay of > 0 minutes but were not overall delayed) and weather delay >0 minutes (regardless of other delay reasons), the flight was labelled as delayed due to weather. This feature was used to calculate the percentage of flights delayed due to weather."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d32d85ee-0fb3-41cf-ace6-1ea9caa8c8fb"}}},{"cell_type":"code","source":["#UDF to Indicate delayed flight due to weather\ndef weatherdelay_indicate(delayed,minutes):\n  if minutes != None:\n    if delayed == 1 and minutes > 0:\n      weather_delay = 1\n      print(\"minutes:\", minutes)\n    else:\n      weather_delay = 0\n  else:\n    weather_delay = 0\n  return weather_delay\nwdelayUDF = udf(lambda z,y: weatherdelay_indicate(z,y),IntegerType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c709cf12-807c-4a45-a157-1aecfaf1dff0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_airlines_final2= airlines_delay_huborigin_12.withColumn(\"weath_delay\", wdelayUDF(sf.col(\"DEP_DEL15\"),(\"WEATHER_DELAY\")))\ndisplay(df_airlines_final2) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"62823219-52a5-4700-aa95-9487c6279e17"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#confriming % of flights delayed due to weather based on our definition\nwdelay_table = df_airlines_final2.groupBy(\"weath_delay\").count().show()\nweath_delay = df_airlines_final2.crosstab('DEP_DEL15', 'weath_delay').show()\nweath_delay"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"219a6e76-b631-4230-a529-61d3678a1fd0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["hours = lambda i: i * 3600\nw = Window().partitionBy(sf.col(\"ORIGIN\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(1), 0)\ndf_airlines_final3 = df_airlines_final2.withColumn('total_flights_perhr', sf.count(\"ORIGIN_AIRPORT_ID\").over(w))\n#display(df_airlines_final3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"448f786e-4db2-4cf8-bd4f-4f3a8c49bf41"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["w = Window().partitionBy(sf.col(\"ORIGIN\")).orderBy(sf.col(\"depart_unix_prior2hr\")).rangeBetween(-hours(1), 0)\ndf_airlines_final4 = df_airlines_final3.withColumn('total_w_delay', sf.sum(\"weath_delay\").over(w))\n#display(df_airlines_final4)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b1e78f6a-375d-4343-ae7c-e207daf4c922"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_airlines_final5 = df_airlines_final4.withColumn('percent_wdelay',(df_airlines_final4.total_w_delay/df_airlines_final4.total_flights_perhr)*100)\ndisplay(df_airlines_final5) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8cdea48a-63bb-4855-99c9-743e80320c0d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Checkpoint \n\nTo reduce running time given how big the dataset is we created a checkpoint, pushed interim dataset to the blob and then pulled from the blob to create further features."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"615bd71f-1744-448f-a466-f475c97c7c6b"}}},{"cell_type":"code","source":["#Write interim dataframe to the blob\ndf_airlines_final5.write.parquet(f\"{blob_url}/df_airlines_final_full_v1\")\n\n# Load interim flights data from the blob\ndf_airlines_finalb = spark.read.parquet(f\"{blob_url}/df_airlines_final_full_v1\")\ndisplay(df_airlines_finalb)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e162dba-571d-4c52-bc5a-35ab486f2d1b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Testing correct data counts from Blob\nOur team had some issue with writing ot the blob and our data was reduced while writing to the blob. We tested data from this checkpoint ot make sure we did not run into any issues."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88c95d9b-a337-40de-af45-f9148e18b0c9"}}},{"cell_type":"code","source":["#test data from blob\ndf_airlines_finalb.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cc53a4ba-0c1e-4880-8fb5-aa22c40786b4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Check Number of flights delayed due to weather is same as before pushing to blob - Testing\nwdelay_table = df_airlines_finaltest.groupBy(\"weath_delay\").count().show()\nweath_delay = df_airlines_finaltest.crosstab('DEP_DEL15', 'weath_delay').show()\nweath_delay"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b35d365-b91f-4047-acf1-8b79cd70302a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Feature reflecting part of the day (Morning etc.)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"371a86eb-3c3f-4c7e-be62-1249e8a06f03"}}},{"cell_type":"code","source":["# Adding part of the day feature\nimport datetime\nfrom datetime import *\n\n#UDf to extract hour from hh:mm format\ndef hour_convert(time):\n  try:\n    time_split = datetime.strptime(str(time), \"%H%M\")\n    hr = time_split.hour\n  except:\n    hr = int(time)\n  return hr\n\n#UDF to classify part of the day using hour\ndef part_of_day(hr):\n  day_part = 0\n  if hr >= 5 and hr < 12:\n    day_part = \"Morning\"\n  elif hr >= 12 and hr < 17:\n    day_part = \"Afteroon\"\n  elif hr >= 17 and hr < 21:\n    day_part = \"Evening\"\n  else:\n    day_part = \"Night\"\n  return day_part\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"756c51e7-16d2-4ab8-961f-3227fca6d1cc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Apply hour and day part UDF to dataframe\nHourUDF = udf(lambda z: hour_convert(z),IntegerType())\npartUDF = udf(lambda z: part_of_day(z), StringType())\ndf_airlines_finalb1= df_airlines_finalb.withColumn(\"DEP_HOUR\", HourUDF(sf.col(\"CRS_DEP_TIME\")))\ndisplay(df_airlines_finalb1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26104a7f-47ca-412f-b6e4-62f1a04da48b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_airlines_finalb2 = df_airlines_finalb1.withColumn(\"Part_of_Day\", partUDF(sf.col(\"DEP_HOUR\")))\ndisplay(df_airlines_finalb2)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b4d05b5-8098-4182-b47f-ce1e3a33d2a1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Confirm part of the day and hours match\nhr_table = df_airlines_finalb2.groupBy(\"DEP_HOUR\").count().show()\nhr_part = df_airlines_finalb2.crosstab('DEP_HOUR', 'PART_of_Day').show()\nhr_part"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74f4dfbc-6063-4c62-92a6-fc042977285b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Final Dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fec28437-dc06-4d48-9258-8df00edce6a4"}}},{"cell_type":"code","source":["#Final DataFrame\n# dataframe.write.fileformat(f\"{blob_url}\")\ndf_airlines_finalb2.write.parquet(f\"{blob_url}/df_airlines_final_full_v7\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"187ea68e-9457-4a89-b454-afc97b7435f5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#confirm if pushed to the blob\ndisplay(dbutils.fs.ls(blob_url))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8ccf6109-1e8e-4738-a789-908966f3f42c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Help links and References\n\nOperations (aggregation, cumulative sum, rolling windows):\n- https://excelkingdom.blogspot.com/2017/12/how-to-calculate-cumulative-sum-or_15.html\n- https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/968100988546031/157591980591166/8836542754149149/latest.html\n- https://stackoverflow.com/questions/45806194/pyspark-rolling-average-using-timeseries-data\n- https://www.analyticsvidhya.com/blog/2019/12/6-powerful-feature-engineering-techniques-time-series/\n- https://stackoverflow.com/questions/45946349/python-spark-cumulative-sum-by-group-using-dataframe\n- https://stackoverflow.com/questions/60869614/pyspark-how-to-extract-hour-from-timestamp \n\n\nDatetime conversion:\n- https://www.kite.com/python/answers/how-to-convert-local-datetime-to-utc-in-python \n\nUDF's in PySpark:\n- https://sparkbyexamples.com/pyspark/pyspark-udf-user-defined-function/\n\nSyllabus link:\n- https://docs.google.com/document/d/1BTbc6znZe3wTpdIVeun66K8AkzUlfYW1dlDPZkbZ5NM/edit\n\nProject doc:\n- https://docs.google.com/document/d/1eViHlmcDUCqse482TE8ReFth7koQa4C1wLP-EBqKRGY/edit\n\nEDA:\n- https://towardsdatascience.com/a-practical-guide-for-exploratory-data-analysis-flight-delays-f8a713ef7121 \n\nColumns of Interest: \n- FL_DATE, OP_UNIQUE_CARRIER, OP_CARRIER_AIRLINE_ID, TAIL_NUM, ORIGIN, ORIGIN_AIRPORT_ID, ORIGIN_CITY_NAME, DEST_AIRPORT_ID, DEST, DEST_CITY_NAME, DEP_TIME, DEP_DELAY, DEP_DEL15, ARR_TIME, ARR_DELAY, ARR_DEL15, CANCELLED, CANCELLATION_CODE, DIVERTED, AIR_TIME, FLIGHTS, DISTANCE, CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY, DIVE_AIRPORT_LANDINGS\n\nDEPENDENT VARIABLE:\n- DEP_DEL15 (1- IF flight is 15 min delayed, 0 otherwise)\n\nDataset Links:\n- Link: https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGK\n- Link to data dictionary: https://www.transtats.bts.gov/Glossary.asp?index=C \n- Flights data helpful link: https://www.transtats.bts.gov/homepage.asp"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b649ed6e-9035-42f5-b879-fbaed9e897af"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"starter_nb_fp_KM_v2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2164382306191135}},"nbformat":4,"nbformat_minor":0}
