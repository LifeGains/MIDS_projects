{"cells":[{"cell_type":"markdown","source":["# Algorithm Exploration"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"83f703a1-474d-4ae0-a576-15b70983afd0"}}},{"cell_type":"markdown","source":["This notebook implements Logistic Regression, Random Forest, SVM and Gradient Boosting Tree to our delayed flights dataset.\n\n<a href='$./fp_main_notebook_final'>To return to main notebook click here</a>."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41826926-ce31-4f8c-85f1-becf98fd0668"}}},{"cell_type":"markdown","source":["## Set-up blob storage"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5810830a-c466-4661-b9d3-27d4eb6ce04c"}}},{"cell_type":"code","source":["# init script to create the blob URL\nblob_container = 'team07'\nstorage_account = 'team07'\nsecret_scope = 'team07'\nsecret_key = 'team07'\nblob_url = f'wasbs://{blob_container}@{storage_account}.blob.core.windows.net'\n\n# generates the SAS token\nspark.conf.set(\n  f'fs.azure.sas.{blob_container}.{storage_account}.blob.core.windows.net',\n  dbutils.secrets.get(scope = secret_scope, key = secret_key)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ab94bf9-1787-430a-a4d9-ff3e997f84c6"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Run imports"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1935238-ef60-4c67-b8ff-4934770338d1"}}},{"cell_type":"code","source":["# imports\nimport numpy as np\nimport pandas as pd\nimport random\nimport time\nimport matplotlib.pyplot as plt\nfrom itertools import chain\nfrom pyspark.sql import Row, Column\nfrom pyspark.sql.types import BooleanType\nfrom pyspark.sql.functions import *\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\nfrom pyspark.ml.feature import StandardScaler, Imputer\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier, LinearSVC\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f29f754-0be2-4d3a-895b-36f26c917803"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Import the joined data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f55efe61-914a-48b1-a74a-ca8841460220"}}},{"cell_type":"markdown","source":["We have a check-point at the blob storage with the data ready for modelling."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"702336d1-215d-4085-a207-351b374809fa"}}},{"cell_type":"code","source":["# read joined dataset\nrawDataDF = spark.read.parquet(f'{blob_url}/joined_data_all_v1')\n\n# print out number of rows\nprint(str(rawDataDF.count()) + ' rows in the data.')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1bf292f4-3b64-4ce0-b816-264d94612e77"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Filter columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f96827de-0aad-46a1-ab5c-4eb8cb786e94"}}},{"cell_type":"markdown","source":["Filter only columns of interest."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c4927011-232e-435e-9fe9-58f3d40058de"}}},{"cell_type":"code","source":["# label and features of interest\ncols = ['DEP_DEL15', 'YEAR', 'QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'OP_CARRIER', 'ORIGIN', 'DEST', 'rolling_average', 'delay_2hrs_originport', 'delay_4hrs_originport', 'delay_8hrs_originport', 'delay_12hrs_originport', 'delay_2hrs_destport', 'delay_4hrs_destport', 'delay_8hrs_destport', 'delay_12hrs_destport', 'delay_2hrs_orgairline', 'delay_4hrs_orgairline', 'delay_8hrs_orgairline', 'delay_12hrs_orgairline', 'arrdelay_2hrs_originport', 'arrdelay_4hrs_originport', 'arrdelay_8hrs_originport', 'arrdelay_12hrs_originport', 'delay_2hrs_originhub', 'delay_4hrs_originhub', 'delay_8hrs_originhub', 'delay_12hrs_originhub', 'DEP_HOUR', 'Part_of_Day', 'WND_direction_angle', 'WND_speed', 'CIG_ceiling_height_dimension', 'VIS_distance_dimension', 'TMP_air_temperature', 'DEW_dew_point_temperature', 'SLP_sea_level_pressure', 'Bad_Weather_Prediction']\n\n# filter cols of interest\nfilteredDataDF = rawDataDF.select(cols).cache()\n\n# print out number of features\n# minus two to account for the response and the year variables (which will only be used for splitting)\nprint(str(len(filteredDataDF.columns)-2) + ' features in the data.')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b99d3df-0fbd-4270-bf25-e3c88cbc7d00"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Split train and test data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cdf5f53d-cdd9-4a00-a160-76b3589ca635"}}},{"cell_type":"code","source":["# set 2019 as the hold-out test set\nhold_out_variable = 'YEAR'\nhold_out_threshold = '2019'\n\n# split train and test sets\ntrainDF = filteredDataDF.filter(filteredDataDF[hold_out_variable]!=hold_out_threshold).cache()\ntestDF = filteredDataDF.filter(filteredDataDF[hold_out_variable]==hold_out_threshold).cache()\n\n# print count of rows\ntrain_years = sorted([x[0] for x in trainDF.select(hold_out_variable).distinct().collect()])\ntest_years = sorted([x[0] for x in testDF.select(hold_out_variable).distinct().collect()])\nprint(f'{trainDF.count()} rows in the train data, representing {hold_out_variable.lower()}s: {str(train_years)[1:-1]}.')\nprint(f'{testDF.count()} rows in the test data, representing {hold_out_variable.lower()}s: {str(test_years)[1:-1]}.')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c827d8c-c998-4162-ab1d-782f38eb59f8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Oversample minority class"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f35b2106-4cf6-4eed-8c3c-c060b32cb040"}}},{"cell_type":"markdown","source":["Given our data is unbalanced (most of flights do not delay) we will do random oversampling in the minority class aiming to get to a 50-50% class balance in the training dataset."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e712dc4-8cbb-424c-850a-c8fc4f6f8543"}}},{"cell_type":"code","source":["# split the data given labels\nminor_df = trainDF.filter(col('DEP_DEL15')==1).cache()\nmajor_df = trainDF.filter(col('DEP_DEL15')==0).cache()\n\n# compute the ratio between on-time and delayed flights\nn_ontime = major_df.count()\nn_delays = minor_df.count()\nratio = n_ontime/n_delays\nprint('The ratio of on-time to delayed flights is of {:0.2f}:1'.format(ratio))\n\n# oversample the delayed flights\noversample_df = minor_df.sample(withReplacement=True, fraction=ratio, seed=123)\naugmentedTrainDF = major_df.unionAll(oversample_df).cache()\naugmentedTrainDF.groupBy('DEP_DEL15').count().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5cc808ed-8eac-4fd6-95f9-c8b4e3f7a2f9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Split CV folds in the train data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"370a68b1-a950-43cc-b3bc-8d98152801a3"}}},{"cell_type":"markdown","source":["Creates a `foldCol` which specifies how we want to fold the data for cross-validation."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"170c07d4-cc7f-45af-8510-be1a7dcb4358"}}},{"cell_type":"code","source":["# extract number of distinct YEARS in the training data and create a map\nfold_variable = 'YEAR'\nfold_list = augmentedTrainDF.select(fold_variable).distinct().toPandas()[fold_variable]\nmapping = {x: x - fold_list.min() for x in fold_list}\nprint(f'{fold_variable.capitalize()}, fold_number mapping: {mapping}')\n\n# define number of Folds as nYEARS - 1\nnFolds = len(fold_list) - 1\nprint(f'Total number of folds: {nFolds}')\n\n# add 'foldCol' to TrainDF\nmapping_expr = create_map([lit(x) for x in chain(*mapping.items())])\nfoldedTrainDF = augmentedTrainDF.withColumn('foldCol', mapping_expr[col(fold_variable)]).cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bf33d212-fb18-4b81-92d9-3da14b31d2f2"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Customize CrossValidator creating TimeSeriesCrossValidator"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a87ab27-b381-4c6b-a0c3-b85a30bba95a"}}},{"cell_type":"markdown","source":["Pyspark ML supports model selection through k-fold Cross Validation, but has not built-in methods for Time Series Cross Validation. In order to take benefit of a single Pyspark Pipeline, we decided to customize the CrossValidator class in order to change it behavior and made it supportive of Time Series Cross Validation. The method we will be using is Cross Validation on a Rolling Basis. We will define our training data splits by year. We will then use 2015 to train, and predict 2016. Then we will use 2015 and 2016 to train, and predict 2017. Lastly we will use 2015, 2016 and 2017 to train, and predict 2018. We are going to have a total of 3 kFolds / models. Performance metrics will be averaged for the 3 models for model selection purposes. Pyspark ML already allows the user to specify how it wants fold the data (user-specified fold numbers vs. random split) by using the `foldCol` argument, but the standard behavior still trains the model in all other folds except the fold selected for validation. In order to change this behavior, we will need to do an small change in the method `_kFold`. We will specify that the training folds must always come before the validation fold (never after). All the other functionalities of the class will be kept intact to ensure a smooth integration with the rest of the Pyspark Pipeline."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7256efa-5ac2-4ba4-a097-16a07a6fd14d"}}},{"cell_type":"code","source":["class TimeSeriesCrossValidator(CrossValidator):\n    '''\n    Customizes CrossValidator to perform time series cross validation on a rolling basis.\n    User needs to provide `foldCol` with the fold numbers defined in a time ascending order\n    (e.g. 2015 is assigned as fold 0, 2016 as fold 1, and so on).\n    '''\n    def _kFold(self, dataset):\n        nFolds = self.getOrDefault(self.numFolds)\n        foldCol = self.getOrDefault(self.foldCol)\n\n        datasets = []\n        if not foldCol:\n            # Do random k-fold split.\n            seed = self.getOrDefault(self.seed)\n            h = 1.0 / nFolds\n            randCol = self.uid + \"_rand\"\n            df = dataset.select(\"*\", rand(seed).alias(randCol))\n            for i in range(nFolds):\n                validateLB = i * h\n                validateUB = (i + 1) * h\n                condition = (df[randCol] >= validateLB) & (df[randCol] < validateUB)\n                validation = df.filter(condition)\n                train = df.filter(~condition)\n                datasets.append((train, validation))\n        else:\n            # Use user-specified fold numbers.\n            def checker(foldNum):\n                if foldNum < 0 or foldNum > nFolds:\n                    raise ValueError(\n                        \"Fold number must be in range [0, %s], but got %s.\" % (nFolds, foldNum)\n                    )\n                return True\n\n            checker_udf = UserDefinedFunction(checker, BooleanType())\n            for i in range(nFolds):\n                training = dataset.filter(checker_udf(dataset[foldCol]) & (col(foldCol) <= lit(i))) # Training set always in the past\n                validation = dataset.filter(\n                    checker_udf(dataset[foldCol]) & (col(foldCol) == lit(i+1)) # Validation set always in the future\n                )\n                if training.rdd.getNumPartitions() == 0 or len(training.take(1)) == 0:\n                    raise ValueError(\"The training data at fold %s is empty.\" % i)\n                if validation.rdd.getNumPartitions() == 0 or len(validation.take(1)) == 0:\n                    raise ValueError(\"The validation data at fold %s is empty.\" % i)\n                datasets.append((training, validation))\n\n        return datasets"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16162df5-5fd9-4f6e-9611-65c6a9d8e2cf"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Logistic Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a839aef-5939-4d01-9df5-d3fb17e6d434"}}},{"cell_type":"markdown","source":["## Set the pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"932d0703-1cc7-44e6-b6cc-0f5ff2797352"}}},{"cell_type":"code","source":["# define categorical and continuous variables\ncategoricals = ['QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DEP_HOUR', 'OP_CARRIER', 'ORIGIN', 'DEST', 'Bad_Weather_Prediction']\nnumerics = ['rolling_average', 'delay_2hrs_originport', 'delay_4hrs_originport', 'delay_8hrs_originport', 'delay_12hrs_originport', 'delay_2hrs_destport', 'delay_4hrs_destport', 'delay_8hrs_destport', 'delay_12hrs_destport', 'delay_2hrs_orgairline', 'delay_4hrs_orgairline', 'delay_8hrs_orgairline', 'delay_12hrs_orgairline', 'arrdelay_2hrs_originport', 'arrdelay_4hrs_originport', 'arrdelay_8hrs_originport', 'arrdelay_12hrs_originport', 'delay_2hrs_originhub', 'delay_4hrs_originhub', 'delay_8hrs_originhub', 'delay_12hrs_originhub', 'WND_direction_angle', 'WND_speed', 'CIG_ceiling_height_dimension', 'VIS_distance_dimension', 'SLP_sea_level_pressure', 'TMP_air_temperature', 'DEW_dew_point_temperature']\n\n# define feature transformations\nindexer = map(lambda c: StringIndexer(inputCol=c, outputCol=c+'_idx', handleInvalid = 'keep'), categoricals)\nohes = map(lambda c: OneHotEncoder(inputCol=c+'_idx', outputCol=c+'_class'), categoricals)\nimputer = Imputer(strategy='median', inputCols = numerics, outputCols = numerics)\nfeature_cols = list(map(lambda c: c+'_idx', categoricals)) + numerics\nvassembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\nscaler = StandardScaler(inputCol='features', outputCol='scaledFeatures',\n                        withStd=True, withMean=True)\n\n# create a map of {idx: count of distinct values} for the categorial features\ncat_features_map = {idx: trainDF.select(categoricals[idx]).distinct().count() for idx in range(len(categoricals))}\nmax_dist_values = sorted(cat_features_map.values())[-1]+1\n\n# set-up the algorithm\nlr = LogisticRegression(featuresCol='scaledFeatures', labelCol='DEP_DEL15', maxIter=100, regParam=0.1, elasticNetParam=0.5, \n                        standardization=False, family='binomial')\n# assemble the pipeline\nlr_transf_stages = list(indexer) + list(ohes) + [imputer] + [vassembler] + [scaler] + [lr]\nlr_pipeline = Pipeline(stages=lr_transf_stages)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3584183-b341-468a-b88f-a6061967f614"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Select best model using TimeSeriesCrossValidator"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29ed8461-4443-48b6-bae1-e4e4fedba804"}}},{"cell_type":"code","source":["# build the parameter grid for model tuning\nlr_paramGrid = ParamGridBuilder() \\\n              .addGrid(lr.regParam, [0.01, 0.1]) \\\n              .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n              .build()\n\n# execute TimeSeriesCrossValidator for model tuning\nlr_crossval = TimeSeriesCrossValidator(estimator=lr_pipeline,\n                          estimatorParamMaps=lr_paramGrid,\n                          evaluator=BinaryClassificationEvaluator(labelCol='DEP_DEL15', \n                                                                  metricName='areaUnderROC'),\n                          parallelism=3,\n                          foldCol='foldCol',\n                          numFolds=nFolds)\n\n# train the tuned model and establish our best model\nstart = time.time()\nlr_cvModel = lr_crossval.fit(foldedTrainDF)\nlr_model = lr_cvModel.bestModel\nprint(f'CV-training time: {time.time() - start} seconds')\nprint('')\n\n# print best model params\nprint(f'Best Param (maxIter): {lr_model.stages[-1].getMaxIter()}')\nprint(f'Best Param (regParam): {lr_model.stages[-1].getRegParam()}')\nprint(f'Best Param (elasticNetParam): {lr_model.stages[-1].getElasticNetParam()}')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a6f9010d-0722-44eb-a6ab-867769c8214d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evalute results in the training set"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3bf5cf0-c281-418d-b8d9-8933e7650800"}}},{"cell_type":"code","source":["# evaluate results in the training set\npredictions = lr_model.transform(trainDF.filter(trainDF.DEP_DEL15.isNotNull()))\neval_ = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='DEP_DEL15')\n\n# store performance metrics in a dictionary\nmetrics = ['accuracy', 'weightedPrecision', 'weightedRecall', 'weightedFMeasure', 'precisionByLabel', 'recallByLabel', 'fMeasureByLabel']\nresults = {}\nfor m in metrics:\n  if m in ['precisionByLabel', 'recallByLabel', 'fMeasureByLabel']:\n    results[m] = [eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:0.0}), \n                  eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:1.0})]\n  else:\n    results[m] = eval_.evaluate(predictions, {eval_.metricName: m})\n\n# print results\nprint('Performance metrics - TRAINING SET')\nprint('------------------------------------------------------------------------------------------------')\nfor x in results:\n  print(f'{x}: {results[x]}')\n  \n# save results\nlr_train = results"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7d6c5dc-3f56-4db8-a76a-3888a34e028b"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evaluate results in the test set"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a563a451-6b2f-4c5d-9271-d54f16ea5925"}}},{"cell_type":"code","source":["# evaluate results in the test set\npredictions = lr_model.transform(testDF)\neval_ = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='DEP_DEL15')\n\n# store performance metrics in a dictionary\nmetrics = ['accuracy', 'weightedPrecision', 'weightedRecall', 'weightedFMeasure', 'precisionByLabel', 'recallByLabel', 'fMeasureByLabel']\nresults = {}\nfor m in metrics:\n  if m in ['precisionByLabel', 'recallByLabel', 'fMeasureByLabel']:\n    results[m] = [eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:0.0}), \n                  eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:1.0})]\n  else:\n    results[m] = eval_.evaluate(predictions, {eval_.metricName: m})\n\n# print results\nprint('Performance metrics - TEST SET')\nprint('------------------------------------------------------------------------------------------------')\nfor x in results:\n  print(f'{x}: {results[x]}')\n  \n# save results\nlr_test = results"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d1e2acc0-746e-485e-8856-d8ec4c92cc5a"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Random Forest Classfier"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2bdab59b-a69d-4f91-ac1e-76698d211022"}}},{"cell_type":"markdown","source":["## Set the pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"98fce7a0-bfca-4749-81fd-0f23ca1d7871"}}},{"cell_type":"code","source":["# define categorical and continuous variables\ncategoricals = ['QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DEP_HOUR', 'OP_CARRIER', 'ORIGIN', 'DEST', 'Bad_Weather_Prediction']\nnumerics = ['rolling_average', 'delay_2hrs_originport', 'delay_4hrs_originport', 'delay_8hrs_originport', 'delay_12hrs_originport', 'delay_2hrs_destport', 'delay_4hrs_destport', 'delay_8hrs_destport', 'delay_12hrs_destport', 'delay_2hrs_orgairline', 'delay_4hrs_orgairline', 'delay_8hrs_orgairline', 'delay_12hrs_orgairline', 'arrdelay_2hrs_originport', 'arrdelay_4hrs_originport', 'arrdelay_8hrs_originport', 'arrdelay_12hrs_originport', 'delay_2hrs_originhub', 'delay_4hrs_originhub', 'delay_8hrs_originhub', 'delay_12hrs_originhub', 'WND_direction_angle', 'WND_speed', 'CIG_ceiling_height_dimension', 'VIS_distance_dimension', 'SLP_sea_level_pressure', 'TMP_air_temperature', 'DEW_dew_point_temperature']\n\n# define feature transformations\nindexer = map(lambda c: StringIndexer(inputCol=c, outputCol=c+'_idx', handleInvalid = 'keep'), categoricals)\nohes = map(lambda c: OneHotEncoder(inputCol=c+'_idx', outputCol=c+'_class'), categoricals)\nimputer = Imputer(strategy='median', inputCols = numerics, outputCols = numerics)\nfeature_cols = list(map(lambda c: c+'_idx', categoricals)) + numerics\nvassembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\nscaler = StandardScaler(inputCol='features', outputCol='scaledFeatures',\n                        withStd=True, withMean=True)\n\n# create a map of {idx: count of distinct values} for the categorial features\ncat_features_map = {idx: trainDF.select(categoricals[idx]).distinct().count() for idx in range(len(categoricals))}\nmax_dist_values = sorted(cat_features_map.values())[-1]+1\n\n# set-up the algorithm\nrfw = RandomForestClassifier(featuresCol='features', labelCol='DEP_DEL15', numTrees = 500, featureSubsetStrategy='sqrt', \n                             maxDepth=6, maxBins=max_dist_values, impurity='gini', seed=123)\n# assemble the pipeline\nrfw_transf_stages = list(indexer) + [imputer] + [vassembler] + [rfw]\nrfw_pipeline = Pipeline(stages=rfw_transf_stages)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d8fff191-271e-4999-81a9-f01538e54649"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Select best model using TimeSeriesCrossValidator"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e3daa8a5-0bcc-4371-b2cd-a022754579ac"}}},{"cell_type":"code","source":["# build the parameter grid for model tuning\nrfw_paramGrid = ParamGridBuilder() \\\n               .addGrid(rfw.numTrees, [100, 500]) \\\n               .addGrid(rfw.maxDepth, [4, 8]) \\\n               .build()\n\n# execute TimeSeriesCrossValidator for model tuning\nrfw_crossval = TimeSeriesCrossValidator(estimator=rfw_pipeline,\n                          estimatorParamMaps=rfw_paramGrid,\n                          evaluator=BinaryClassificationEvaluator(labelCol='DEP_DEL15', \n                                                                  metricName='areaUnderROC'),\n                          parallelism=3,\n                          foldCol='foldCol',\n                          numFolds=nFolds)\n\n# train the tuned model and establish our best model\nstart = time.time()\nrfw_cvModel = rfw_crossval.fit(foldedTrainDF)\nrfw_model = rfw_cvModel.bestModel\nprint(f'CV-training time: {time.time() - start} seconds')\nprint('')\n\n# print best model params\nprint(f'Best Param (numTrees): {rfw_model.stages[-1].getNumTrees}')\nprint(f'Best Param (maxDepth): {rfw_model.stages[-1].getMaxDepth()}')\nprint(f'Best Param (featureSubsetStrategy): {rfw_model.stages[-1].getFeatureSubsetStrategy()}')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37815188-4177-41dd-ac3b-9afb826e5e3e"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evalute results in the training set"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"23f8d853-1b2d-4b4e-8206-8efe149b6190"}}},{"cell_type":"code","source":["# evaluate results in the training set\npredictions = rfw_model.transform(trainDF.filter(trainDF.DEP_DEL15.isNotNull()))\neval_ = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='DEP_DEL15')\n\n# store performance metrics in a dictionary\nmetrics = ['accuracy', 'weightedPrecision', 'weightedRecall', 'weightedFMeasure', 'precisionByLabel', 'recallByLabel', 'fMeasureByLabel']\nresults = {}\nfor m in metrics:\n  if m in ['precisionByLabel', 'recallByLabel', 'fMeasureByLabel']:\n    results[m] = [eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:0.0}), \n                  eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:1.0})]\n  else:\n    results[m] = eval_.evaluate(predictions, {eval_.metricName: m})\n\n# print results\nprint('Performance metrics - TRAINING SET')\nprint('------------------------------------------------------------------------------------------------')\nfor x in results:\n  print(f'{x}: {results[x]}')\n  \n# save results\nrfw_train = results"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b1913861-53d8-43f4-a0e4-cd17002165ec"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evaluate results in the test set"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8da36992-917b-44e7-a920-a688f27f6bde"}}},{"cell_type":"code","source":["# evaluate results in the test set\npredictions = rfw_model.transform(testDF)\neval_ = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='DEP_DEL15')\n\n# store performance metrics in a dictionary\nmetrics = ['accuracy', 'weightedPrecision', 'weightedRecall', 'weightedFMeasure', 'precisionByLabel', 'recallByLabel', 'fMeasureByLabel']\nresults = {}\nfor m in metrics:\n  if m in ['precisionByLabel', 'recallByLabel', 'fMeasureByLabel']:\n    results[m] = [eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:0.0}), \n                  eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:1.0})]\n  else:\n    results[m] = eval_.evaluate(predictions, {eval_.metricName: m})\n\n# print results\nprint('Performance metrics - TEST SET')\nprint('------------------------------------------------------------------------------------------------')\nfor x in results:\n  print(f'{x}: {results[x]}')\n  \n# save results\nrfw_test = results"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbb8cff3-d968-4194-9fcf-92618195b107"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Linear SVM"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3ccee08f-7d16-4535-9a5e-57b0e74350f6"}}},{"cell_type":"markdown","source":["## Set the pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e917db8-bdd8-4c03-b206-5a113a322c4c"}}},{"cell_type":"code","source":["# define categorical and continuous variables\ncategoricals = ['QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DEP_HOUR', 'OP_CARRIER', 'ORIGIN', 'DEST', 'Bad_Weather_Prediction']\nnumerics = ['rolling_average', 'delay_2hrs_originport', 'delay_4hrs_originport', 'delay_8hrs_originport', 'delay_12hrs_originport', 'delay_2hrs_destport', 'delay_4hrs_destport', 'delay_8hrs_destport', 'delay_12hrs_destport', 'delay_2hrs_orgairline', 'delay_4hrs_orgairline', 'delay_8hrs_orgairline', 'delay_12hrs_orgairline', 'arrdelay_2hrs_originport', 'arrdelay_4hrs_originport', 'arrdelay_8hrs_originport', 'arrdelay_12hrs_originport', 'delay_2hrs_originhub', 'delay_4hrs_originhub', 'delay_8hrs_originhub', 'delay_12hrs_originhub', 'WND_direction_angle', 'WND_speed', 'CIG_ceiling_height_dimension', 'VIS_distance_dimension', 'SLP_sea_level_pressure', 'TMP_air_temperature', 'DEW_dew_point_temperature']\n\n# define feature transformations\nindexer = map(lambda c: StringIndexer(inputCol=c, outputCol=c+'_idx', handleInvalid = 'keep'), categoricals)\nohes = map(lambda c: OneHotEncoder(inputCol=c+'_idx', outputCol=c+'_class'), categoricals)\nimputer = Imputer(strategy='median', inputCols = numerics, outputCols = numerics)\nfeature_cols = list(map(lambda c: c+'_idx', categoricals)) + numerics\nvassembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\nscaler = StandardScaler(inputCol='features', outputCol='scaledFeatures',\n                        withStd=True, withMean=True)\n\n# create a map of {idx: count of distinct values} for the categorial features\ncat_features_map = {idx: trainDF.select(categoricals[idx]).distinct().count() for idx in range(len(categoricals))}\nmax_dist_values = sorted(cat_features_map.values())[-1]+1\n\n# set-up the algorithm\nsvm = LinearSVC(featuresCol='scaledFeatures', labelCol='DEP_DEL15', \n                maxIter=100, regParam=0.1, standardization=False)\n\n# assemble the pipeline\nsvm_transf_stages = list(indexer) + list(ohes) + [imputer] + [vassembler] + [scaler] + [svm]\nsvm_pipeline = Pipeline(stages=svm_transf_stages)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4110aa48-b2dd-44b7-b56f-31d41b6a00a5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Select best model using TimeSeriesCrossValidator"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d8faacc8-5e16-4c18-ba5e-45cd77554eb0"}}},{"cell_type":"code","source":["# build the parameter grid for model tuning\nsvm_paramGrid = ParamGridBuilder() \\\n               .addGrid(svm.maxIter, [50, 100]) \\\n               .addGrid(svm.regParam, [0.01, 0.1, 1.0]) \\\n               .build()\n\n# execute TimeSeriesCrossValidator for model tuning\nsvm_crossval = TimeSeriesCrossValidator(estimator=svm_pipeline,\n                          estimatorParamMaps=svm_paramGrid,\n                          evaluator=BinaryClassificationEvaluator(labelCol='DEP_DEL15', \n                                                                  metricName='areaUnderROC'),\n                          parallelism=3,\n                          foldCol='foldCol',\n                          numFolds=nFolds)\n\n# train the tuned model and establish our best model\nstart = time.time()\nsvm_cvModel = svm_crossval.fit(foldedTrainDF)\nsvm_model = svm_cvModel.bestModel\nprint(f'CV-training time: {time.time() - start} seconds')\nprint('')\n\n# print best model params\nprint(f'Best Param (maxIter): {svm_model.stages[-1].getMaxIter()}')\nprint(f'Best Param (regParam): {svm_model.stages[-1].getRegParam()}')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72b7de75-a38b-4c91-b7f2-68430844c6f8"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evalute results in the training set"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df4072cd-1dad-4c8e-b7a5-768d6e07ff69"}}},{"cell_type":"code","source":["# evaluate results in the training set\npredictions = svm_model.transform(trainDF.filter(trainDF.DEP_DEL15.isNotNull()))\neval_ = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='DEP_DEL15')\n\n# store performance metrics in a dictionary\nmetrics = ['accuracy', 'weightedPrecision', 'weightedRecall', 'weightedFMeasure', 'precisionByLabel', 'recallByLabel', 'fMeasureByLabel']\nresults = {}\nfor m in metrics:\n  if m in ['precisionByLabel', 'recallByLabel', 'fMeasureByLabel']:\n    results[m] = [eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:0.0}), \n                  eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:1.0})]\n  else:\n    results[m] = eval_.evaluate(predictions, {eval_.metricName: m})\n\n# print results\nprint('Performance metrics - TRAINING SET')\nprint('------------------------------------------------------------------------------------------------')\nfor x in results:\n  print(f'{x}: {results[x]}')\n\n# save results\nsvm_train = results"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"926fb571-c9fc-4ead-9aa5-65403a08a858"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evaluate results in the test set"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f366bf47-9a8d-4d69-8f89-e47f0f7d79d2"}}},{"cell_type":"code","source":["# evaluate results in the test set\npredictions = svm_model.transform(testDF)\neval_ = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='DEP_DEL15')\n\n# store performance metrics in a dictionary\nmetrics = ['accuracy', 'weightedPrecision', 'weightedRecall', 'weightedFMeasure', 'precisionByLabel', 'recallByLabel', 'fMeasureByLabel']\nresults = {}\nfor m in metrics:\n  if m in ['precisionByLabel', 'recallByLabel', 'fMeasureByLabel']:\n    results[m] = [eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:0.0}), \n                  eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:1.0})]\n  else:\n    results[m] = eval_.evaluate(predictions, {eval_.metricName: m})\n\n# print results\nprint('Performance metrics - TEST SET')\nprint('------------------------------------------------------------------------------------------------')\nfor x in results:\n  print(f'{x}: {results[x]}')\n  \n# save results\nsvm_test = results"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d511942d-2936-4936-9624-b55d320ba073"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Gradient Boosting Trees"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7bb1548a-20bd-4c6d-a4a1-ae64e5e6fb8b"}}},{"cell_type":"markdown","source":["## Set the pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"20bd2084-3d10-4965-ad59-970af68f0448"}}},{"cell_type":"code","source":["# define categorical and continuous variables\ncategoricals = ['QUARTER', 'MONTH', 'DAY_OF_MONTH', 'DAY_OF_WEEK', 'DEP_HOUR', 'OP_CARRIER', 'ORIGIN', 'DEST', 'Bad_Weather_Prediction']\nnumerics = ['rolling_average', 'delay_2hrs_originport', 'delay_4hrs_originport', 'delay_8hrs_originport', 'delay_12hrs_originport', 'delay_2hrs_destport', 'delay_4hrs_destport', 'delay_8hrs_destport', 'delay_12hrs_destport', 'delay_2hrs_orgairline', 'delay_4hrs_orgairline', 'delay_8hrs_orgairline', 'delay_12hrs_orgairline', 'arrdelay_2hrs_originport', 'arrdelay_4hrs_originport', 'arrdelay_8hrs_originport', 'arrdelay_12hrs_originport', 'delay_2hrs_originhub', 'delay_4hrs_originhub', 'delay_8hrs_originhub', 'delay_12hrs_originhub', 'WND_direction_angle', 'WND_speed', 'CIG_ceiling_height_dimension', 'VIS_distance_dimension', 'SLP_sea_level_pressure', 'TMP_air_temperature', 'DEW_dew_point_temperature']\n\n# define feature transformations\nindexer = map(lambda c: StringIndexer(inputCol=c, outputCol=c+'_idx', handleInvalid = 'keep'), categoricals)\nohes = map(lambda c: OneHotEncoder(inputCol=c+'_idx', outputCol=c+'_class'), categoricals)\nimputer = Imputer(strategy='median', inputCols = numerics, outputCols = numerics)\nfeature_cols = list(map(lambda c: c+'_idx', categoricals)) + numerics\nvassembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\nscaler = StandardScaler(inputCol='features', outputCol='scaledFeatures',\n                        withStd=True, withMean=True)\n\n# create a map of {idx: count of distinct values} for the categorial features\ncat_features_map = {idx: trainDF.select(categoricals[idx]).distinct().count() for idx in range(len(categoricals))}\nmax_dist_values = sorted(cat_features_map.values())[-1]+1\n\n# set-up the algorithm\ngbt = GBTClassifier(featuresCol='features', labelCol='DEP_DEL15', maxIter=50, stepSize=0.1, maxDepth=1, \n                    maxBins=max_dist_values, featureSubsetStrategy='sqrt', seed=123)\n\n# assemble the pipeline\ngbt_transf_stages = list(indexer) + [imputer] + [vassembler] + [gbt]\ngbt_pipeline = Pipeline(stages=gbt_transf_stages)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2caed6cb-0a3c-4fd4-9005-d9932cceb7d1"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Select best model using TimeSeriesCrossValidator"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc92bdb5-a281-4483-9a4d-7df5ccf81fe0"}}},{"cell_type":"code","source":["# build the parameter grid for model tuning\ngbt_paramGrid = ParamGridBuilder() \\\n               .addGrid(gbt.stepSize, [0.1, 1.0]) \\\n               .addGrid(gbt.maxDepth, [2, 4]) \\\n               .build()\n\n# execute TimeSeriesCrossValidator for model tuning\ngbt_crossval = TimeSeriesCrossValidator(estimator=gbt_pipeline,\n                          estimatorParamMaps=gbt_paramGrid,\n                          evaluator=BinaryClassificationEvaluator(labelCol='DEP_DEL15', \n                                                                  metricName='areaUnderROC'),\n                          parallelism=3,\n                          foldCol='foldCol',\n                          numFolds=nFolds)\n\n# train the tuned model and establish our best model\nstart = time.time()\ngbt_cvModel = gbt_crossval.fit(foldedTrainDF)\ngbt_model = gbt_cvModel.bestModel\nprint(f'CV-training time: {time.time() - start} seconds')\nprint('')\n\n# print best model params\nprint(f'Best Param (maxIter): {gbt_model.stages[-1].getMaxIter()}')\nprint(f'Best Param (stepSize): {gbt_model.stages[-1].getStepSize()}')\nprint(f'Best Param (maxDepth): {gbt_model.stages[-1].getMaxDepth()}')\nprint(f'Best Param (featureSubsetStrategy): {gbt_model.stages[-1].getFeatureSubsetStrategy()}')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5ab29ad-84de-4526-94af-4dc660310335"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evalute results in the training set"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5113387b-7da3-4b45-bcdd-f6bf70d715a8"}}},{"cell_type":"code","source":["# evaluate results in the training set\npredictions = gbt_model.transform(trainDF.filter(trainDF.DEP_DEL15.isNotNull()))\neval_ = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='DEP_DEL15')\n\n# store performance metrics in a dictionary\nmetrics = ['accuracy', 'weightedPrecision', 'weightedRecall', 'weightedFMeasure', 'precisionByLabel', 'recallByLabel', 'fMeasureByLabel']\nresults = {}\nfor m in metrics:\n  if m in ['precisionByLabel', 'recallByLabel', 'fMeasureByLabel']:\n    results[m] = [eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:0.0}), \n                  eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:1.0})]\n  else:\n    results[m] = eval_.evaluate(predictions, {eval_.metricName: m})\n\n# print results\nprint('Performance metrics - TRAINING SET')\nprint('------------------------------------------------------------------------------------------------')\nfor x in results:\n  print(f'{x}: {results[x]}')\n  \n# save results\ngbt_train = results"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e3f965f-7b25-4344-80b7-9bf8f209aaf5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Evaluate results in the test set"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0adc2d2a-8bf6-49ba-a36e-088e0bc862c4"}}},{"cell_type":"code","source":["# evaluate results in the test set\npredictions = gbt_model.transform(testDF)\neval_ = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='DEP_DEL15')\n\n# store performance metrics in a dictionary\nmetrics = ['accuracy', 'weightedPrecision', 'weightedRecall', 'weightedFMeasure', 'precisionByLabel', 'recallByLabel', 'fMeasureByLabel']\nresults = {}\nfor m in metrics:\n  if m in ['precisionByLabel', 'recallByLabel', 'fMeasureByLabel']:\n    results[m] = [eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:0.0}), \n                  eval_.evaluate(predictions, {eval_.metricName: m, eval_.metricLabel:1.0})]\n  else:\n    results[m] = eval_.evaluate(predictions, {eval_.metricName: m})\n\n# print results\nprint('Performance metrics - TEST SET')\nprint('------------------------------------------------------------------------------------------------')\nfor x in results:\n  print(f'{x}: {results[x]}')\n\n# save results\ngbt_test = results"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c318f095-a269-4231-b7d5-ba2969e05ede"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Performance comparison"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"baf006ca-02d3-4d80-b68f-f8d89a1e3a0c"}}},{"cell_type":"markdown","source":["Here we compare the algorithms performance after hyperparameter tuning through TimeSeriesCV."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d91af3b-b7f2-49a5-b85f-8cf03321c5e1"}}},{"cell_type":"code","source":["# plot best model scores\nfig = plt.figure(figsize=(12, 4))\nclassifiers = ['LR', 'RF', 'SVM', 'GBT']\nmetrics = ['recallByLabel', 'fMeasureByLabel', 'precisionByLabel']\ntitles = ['Recall\\n(label 1 = delay)', 'fMeasure\\n(label 1 = delay)', 'Precision\\n(label = delay)']\nnplots = len(metrics)\nresults = [\n  [lr_test[metrics[0]][1],rfw_test[metrics[0]][1],svm_test[metrics[0]][1],gbt_test[metrics[0]][1]],\n  [lr_test[metrics[1]][1],rfw_test[metrics[1]][1],svm_test[metrics[1]][1],gbt_test[metrics[1]][1]],\n  [lr_test[metrics[2]][1],rfw_test[metrics[2]][1],svm_test[metrics[2]][1],gbt_test[metrics[2]][1]],\n]\nfor idx in range(nplots):\n  ax = plt.subplot(1, nplots, idx+1)\n  ax.spines['top'].set_visible(False)\n  ax.spines['right'].set_visible(False)\n  ax.bar(classifiers, results[idx], alpha=0.5)\n  ax.set_ylim(0.0, 1.0)\n  ax.set_title(titles[idx], pad=20)\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d07a210d-ea80-405a-8a7b-44fe8db5220f"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Conclusions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a7681a6-1245-41a5-b78d-98337d7acda9"}}},{"cell_type":"markdown","source":["On our main metric of interest (Recall), the best-performing algorithms were Random Forest and GBT, with Recall slightly above 80%. In terms of fMeasure (out tie-break metric), Gradient Boosting Tree had a slightly better performance, due to its higher Precision compared to Random Forest. So the winner is GBT. GBT is expensive to train, but since we don't antecipate the need for constant retraining this should not be a concern. Prediction time on the other hand takes slighly longer on ensemble models like GBT or RF than on not-emsemble models such as SVM or Logistic Regression. If performance at prediction time is important, this consideration could make us opt for SVM instead, which is as strong as in terms of Recall but slightly less performant in terms of fMeasure and Precision."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52acc3e2-c859-4db0-9e35-2cecef5a55ee"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"fp_algo_exploration_v2","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2164382306191154}},"nbformat":4,"nbformat_minor":0}
